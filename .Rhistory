beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
mse_beta[i] = sum((beta_LS - beta)^2)
}
end.time = proc.time()
print("Sequential version time")
end.time - start.time
?proc.time
start.time2 = proc.time()
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
end.time2 = proc.time()
print("parallel version time")
end.time2 - start.time2
library(foreach)
library(doParallel)
# Dimensions
n = 1000
p = 100
# True vector of coefficients
beta = rep(2, p)
nrep = 1000
# Pre-allocate memory to store errors
mse_beta = rep(NA, nrep)
start.time = proc.time()
# Do for loop over replications
for (i in 1:nrep){
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
mse_beta[i] = sum((beta_LS - beta)^2)
}
end.time = proc.time()
print("Sequential version time")
end.time - start.time
start.time2 = proc.time()
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
end.time2 = proc.time()
print("parallel version time")
end.time2 - start.time2
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
mse_beta
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
mse_beta
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
mse_beta
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
output <- foreach (i = 1:nrep) %dopar% {
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
list(X = X, Y = Y)
}
stopCluster(cl)
length(output)
output[[1]]
names(output[[1]])
getwd()
save(output, file = "DataSim1.Rda")
load("DataSim1.Rda")
?load
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dopar% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dopar% { runif(1) }
stopCluster(cl)
identical(res, res2)
res
res2
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dopar% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dopar% { runif(1) }
stopCluster(cl)
identical(res, res2)
library(doRNG)
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dorng% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dorng% { runif(1) }
stopCluster(cl)
identical(res, res2)
library(doRNG)
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dorng% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dorng% { runif(1) }
stopCluster(cl)
identical(res, res2)
library(doRNG)
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dorng% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dorng% { runif(1) }
stopCluster(cl)
identical(res, res2)
0.25 * 9000
library(glmnet)
?glmnet
install.packages("postGGIR")
remove.packages("MCMCMixBimodal")
library("MCMCMixBimodal")
library("MCMCMixBimodal")
library(MCMCMixBimodal)
devtools::install_github("SrijatoBhattacharyya/MCMCMixBimodal")
library("MCMCMixBimodal")
0.2 * 45
10/45
12/45
13/45
12/45
17/45
14/25
14/45
7/(7 + 5 + 7 + 1)
14/45
5/45
8/45
15/45
(14 + 15)/45
(14 + 18)/45
13/45
14/45
15/45
18/45
8/45
11/45
2/45
3/45
devtools::install_github("minjee-kim/nhanesGraph", build_vignettes = TRUE)
library(nhanesGraph)
library(nhanesGraph)
head(nhanes_table("2008", "EPH", demographics = T, recode = T))
out = nhanes_table("2008", "EPH", demographics = T, recode = T)
?nhanes_table
out = nhanes_table("2022", "EPH", demographics = T, recode = T)
out = nhanes_table("2022", "PEH", demographics = T, recode = T)
out = nhanes_table("2008", "PEH", demographics = T, recode = T)
out = nhanes_table("2008", "EPH", demographics = F, recode = T)
head(out)
nGraph_search()
?nGraph_search
nhanes_viz(graph_type = "hist", file_name = "BPX_D", variable = "BPXSY2")
?nhanes_viz
nhanes_viz(graph_type = "his", file_name = "BPX_D", variable = "BPXSY2")
nhanes_viz(graph_type = "bla", file_name = "BPX_D", variable = "BPXSY2")
nhanes_viz(graph_type = "Hist", file_name = NULL, variable = NULL)
a
nGraph_variable()
?nGraph_variable
year_check
viz
nhanes_variable_list
devtools::install_github("jiayilei/gppcv")
library(standardGP)
library(standardGP)
library(matrixcalc)
# intent inputs
n <- 100 # number of inputs
p <- 10 # number of features
nt <- 50
set.seed(123)
X <- matrix(rnorm(n * p, 0, 0.3), n, p)
y <- matrix(rnorm(n), n, 1)
Xt <- matrix(rnorm(nt * p, 0, 0.3), nt, p)
yt <- matrix(rnorm(nt), nt, 1)
sigma2 <- 10
# first kernel, r is the Euclidean distance between two data points
k1 <- function(r) {
return(exp(-r / 1.5))
}
# second kernel, r is the Euclidean distance between two data points
k2 <- function(r) {
return(exp(-0.5 * (r / 1000)^2))
}
k <- c(k1, k2) # list of kernels
# function output
out <- gpr_seq_kernels(X, y, k, sigma2, Xt, yt)
pick_kernel(list(1), "se")
#> function(r){
#>     return (exp(-0.5 * (r/l)^2))
#>   }
#> <bytecode: 0x0000029dbefcf788>
#> <environment: 0x0000029dbefda6b8>
pick_kernel(list(2, 3), "m")
#> function (r){
#>     left <-  1 / gamma(v) / 2^(v-1)
#>     mid <- (sqrt(2*v)/ l * r)^ v
#>     right <- besselK(sqrt(2*v) * r / l, nu = v)
#>     return (left * mid * right)
#>   }
#> <bytecode: 0x0000029dbf08a438>
#> <environment: 0x0000029dbf097f30>
library(randomForest)
?randomForest
?predict.randomForest
35/40
36/40
26/40
27/40
28/40
32/40
680/8
12 * 7
9 * 3
12 * 2.4
155/12
143/12
143/9
0.2*16
155/12
setwd("~/Documents/irinagain.github.io")
(1/2)/(2/3)
n <- 100
p <- 10
## when joint has weak signal
#q1_weak <- .2
#q2_weak <- .6
#s1_weak <- .2
#s2_weak <- .45
## Pick joint strong signal setting
q1_strong <- .5
q2_strong <- .4
s1_strong <- .6
s2_strong <- .4
# My own combination to play with
#q1_strong <- .7
#q2_strong <- .3
#s1_strong <- .1
#s2_strong <- .3
# average degree of the nodes
avg_deg <- 7.5
# set parameters for model (had 0.3 first)
s <- 0.2 #0.3
k <- sqrt((1-s)^2 + s^2)
a <- matrix(0, 2, 1)
b <- matrix(0, 2, 1)
a[1, ] <- (1 - s) / k
a[2, ] <- s / k
b[1, ] <- a[2, ]
b[2, ] <- a[1, ]
thetas <- acos((2 * (1-s) * s) / k^2) # this is 0.76; pi/2 = 1.57, so this is ~45 degrees or so
# set seed here
set.seed(100000)
# Generate rank 1 joint, rank 1 individual 1, rank 1 individual 2
params <- gen_params(n = n, p = p, q1 = q1_strong, q2 = q2_strong, s1 = s1_strong, s2 = s2_strong, a = a[, 1], b = b[,1], Q=NULL, avg_deg = avg_deg,
joint_sig = 1)
source("~/Library/CloudStorage/GoogleDrive-irinagn@umich.edu/My Drive/Research/2022_Carson_NetworkCovariates/Netdecom.R")
source("~/Library/CloudStorage/GoogleDrive-irinagn@umich.edu/My Drive/Research/2022_Carson_NetworkCovariates/functions.R")
n <- 100
p <- 10
## when joint has weak signal
#q1_weak <- .2
#q2_weak <- .6
#s1_weak <- .2
#s2_weak <- .45
## Pick joint strong signal setting
q1_strong <- .5
q2_strong <- .4
s1_strong <- .6
s2_strong <- .4
# My own combination to play with
#q1_strong <- .7
#q2_strong <- .3
#s1_strong <- .1
#s2_strong <- .3
# average degree of the nodes
avg_deg <- 7.5
# set parameters for model (had 0.3 first)
s <- 0.2 #0.3
k <- sqrt((1-s)^2 + s^2)
a <- matrix(0, 2, 1)
b <- matrix(0, 2, 1)
a[1, ] <- (1 - s) / k
a[2, ] <- s / k
b[1, ] <- a[2, ]
b[2, ] <- a[1, ]
thetas <- acos((2 * (1-s) * s) / k^2) # this is 0.76; pi/2 = 1.57, so this is ~45 degrees or so
# set seed here
set.seed(100000)
# Generate rank 1 joint, rank 1 individual 1, rank 1 individual 2
params <- gen_params(n = n, p = p, q1 = q1_strong, q2 = q2_strong, s1 = s1_strong, s2 = s2_strong, a = a[, 1], b = b[,1], Q=NULL, avg_deg = avg_deg,
joint_sig = 1)
M <- params$M
R1 <- params$R1
R2 <- params$R2
# Here crossprod R1, R2 is exactly cos(theta)
crossprod(R1, R2) #0.72
cos(thetas)  #0.76
# Everything is orthogonal to joint
crossprod(M, R1)
crossprod(M, R2)
crossprod(M)
crossprod(R1)
crossprod(R2)
Z <- params$Z # This is the matrix of latent positions
W <- params$W # This is the mean of X
sum((tcrossprod(svd(W)$u[, 1:2]) - tcrossprod(cbind(M, R2)))^2) # This is zero, correct basis
P <- params$P # This is the probability network matrix
# Here Z is orthogonal but not orthonormal
crossprod(Z) # Not orthonormal though
# Here P has negative entries
min(P)
1490.88/3
install.packages("rGV")
library(rGV)
?mage
mage(x=c(rep(100, 10), rep(120, 10), 105, 85), times=seq(0, 1260, 60))
library(iglu)
library(rGV)
?mage
mage
rGV::mage
