B = 100
#set.seed(230597)
means_boot = matrix(0, B, p)
for (b in 1:B){
xnew = xsamples[sample(1:n, n, replace = TRUE), ]
means_boot[b, ] = colMeans(xnew)
}
var_boot = apply(means_boot, 2, var) #0.0166, 0.0166, 0.014
# Compare the two
plot(var_hat, var_boot, xlim = c(0.008, 0.015), ylim = c(0.008, 0.015))
lines(c(0,1), c(0, 1), col = "red") # bootstrap is smaller, on average
30000/9
?choose
old = choose(33, 3)
old
new = choose(19, 3) + choose(14, 3) + 19 * choose(14, 2) + 14 * choose(19,2) + 19 * 19 * 14 + 14 * 19 * 14
new
new = hoose(19, 3) + choose(14, 3) + 19 * choose(14, 2) + 14 * choose(19, 2)
new = choose(19, 3) + choose(14, 3) + 19 * choose(14, 2) + 14 * choose(19, 2)
new
1990/12
165 + 34
199 * 9
199 * 10
0.9 * 0.8
install.packages("foreach")
install.packages("doParallel")
install.packages("doRNG")
library(foreach)
# Dimensions
n = 100
p = 10
# True vector of coefficients
beta = rep(2, p)
# Set up simulations
nrep = 100
# Pre-allocate memory to store errors
mse_beta = rep(NA, nrep)
# Do for loop over replications
for (i in 1:nrep){
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
mse_beta[i] = sum((beta_LS - beta)^2)
}
mse_beta
mse_beta <- foreach (i = 1:nrep) %do% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
str(mse_beta)
length(mse_beta)
mse_beta[[1]]
mse_beta[[2]]
mse_beta[[3]]
library(foreach)
library(doParallel)
detectCores()
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
?proc.time
rm(list=ls())
library(foreach)
library(doParallel)
# Dimensions
n = 100
p = 10
# True vector of coefficients
beta = rep(2, p)
# Set up simulations
nrep = 100
mse_beta = rep(NA, nrep)
start.time = proc.time()
# Do for loop over replications
for (i in 1:nrep){
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
mse_beta[i] = sum((beta_LS - beta)^2)
}
end.time = proc.time()
print("Sequential version time")
end.time - start.time
?proc.time
start.time2 = proc.time()
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
end.time2 = proc.time()
print("parallel version time")
end.time2 - start.time2
library(foreach)
library(doParallel)
# Dimensions
n = 1000
p = 100
# True vector of coefficients
beta = rep(2, p)
nrep = 1000
# Pre-allocate memory to store errors
mse_beta = rep(NA, nrep)
start.time = proc.time()
# Do for loop over replications
for (i in 1:nrep){
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
mse_beta[i] = sum((beta_LS - beta)^2)
}
end.time = proc.time()
print("Sequential version time")
end.time - start.time
start.time2 = proc.time()
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
end.time2 = proc.time()
print("parallel version time")
end.time2 - start.time2
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
mse_beta
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
mse_beta
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
# foreach loop
mse_beta <- foreach (i = 1:nrep) %dopar% {
# One instance of data generation (making X and Y)
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
# obtain least squares estimator
beta_LS = solve(crossprod(X), crossprod(X,Y))
# calculate estimation error
out = sum((beta_LS - beta)^2)
out
}
stopCluster(cl)
mse_beta
nrep = 5
# Set up the cluster
# Determine the number of workers I can use
nworkers = detectCores() - 1 # for my machine, to leave for other uses
cl <- makeCluster(nworkers)
registerDoParallel(cl)
output <- foreach (i = 1:nrep) %dopar% {
X = matrix(rnorm(n * p, sd = 3), n, p)
Y = X %*% beta + rnorm(n)
list(X = X, Y = Y)
}
stopCluster(cl)
length(output)
output[[1]]
names(output[[1]])
getwd()
save(output, file = "DataSim1.Rda")
load("DataSim1.Rda")
?load
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(2340387)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
set.seed(61234)
nrep = 10
x = rep(NA, nrep)
for (i in 1:nrep){
x[i] = runif(1)
}
x
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dopar% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dopar% { runif(1) }
stopCluster(cl)
identical(res, res2)
res
res2
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dopar% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dopar% { runif(1) }
stopCluster(cl)
identical(res, res2)
library(doRNG)
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dorng% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dorng% { runif(1) }
stopCluster(cl)
identical(res, res2)
library(doRNG)
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dorng% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dorng% { runif(1) }
stopCluster(cl)
identical(res, res2)
library(doRNG)
library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
set.seed(123)
res <- foreach(i=1:5) %dorng% { runif(1) }
set.seed(123)
res2 <- foreach(i=1:5) %dorng% { runif(1) }
stopCluster(cl)
identical(res, res2)
0.25 * 9000
library(glmnet)
?glmnet
install.packages("postGGIR")
remove.packages("MCMCMixBimodal")
library("MCMCMixBimodal")
library("MCMCMixBimodal")
library(MCMCMixBimodal)
devtools::install_github("SrijatoBhattacharyya/MCMCMixBimodal")
library("MCMCMixBimodal")
0.2 * 45
10/45
12/45
13/45
12/45
17/45
14/25
14/45
7/(7 + 5 + 7 + 1)
14/45
5/45
8/45
15/45
(14 + 15)/45
(14 + 18)/45
13/45
14/45
15/45
18/45
8/45
11/45
2/45
3/45
devtools::install_github("minjee-kim/nhanesGraph", build_vignettes = TRUE)
library(nhanesGraph)
library(nhanesGraph)
head(nhanes_table("2008", "EPH", demographics = T, recode = T))
out = nhanes_table("2008", "EPH", demographics = T, recode = T)
?nhanes_table
out = nhanes_table("2022", "EPH", demographics = T, recode = T)
out = nhanes_table("2022", "PEH", demographics = T, recode = T)
out = nhanes_table("2008", "PEH", demographics = T, recode = T)
out = nhanes_table("2008", "EPH", demographics = F, recode = T)
head(out)
nGraph_search()
?nGraph_search
nhanes_viz(graph_type = "hist", file_name = "BPX_D", variable = "BPXSY2")
?nhanes_viz
nhanes_viz(graph_type = "his", file_name = "BPX_D", variable = "BPXSY2")
nhanes_viz(graph_type = "bla", file_name = "BPX_D", variable = "BPXSY2")
nhanes_viz(graph_type = "Hist", file_name = NULL, variable = NULL)
a
nGraph_variable()
?nGraph_variable
year_check
viz
nhanes_variable_list
devtools::install_github("jiayilei/gppcv")
library(standardGP)
library(standardGP)
library(matrixcalc)
# intent inputs
n <- 100 # number of inputs
p <- 10 # number of features
nt <- 50
set.seed(123)
X <- matrix(rnorm(n * p, 0, 0.3), n, p)
y <- matrix(rnorm(n), n, 1)
Xt <- matrix(rnorm(nt * p, 0, 0.3), nt, p)
yt <- matrix(rnorm(nt), nt, 1)
sigma2 <- 10
# first kernel, r is the Euclidean distance between two data points
k1 <- function(r) {
return(exp(-r / 1.5))
}
# second kernel, r is the Euclidean distance between two data points
k2 <- function(r) {
return(exp(-0.5 * (r / 1000)^2))
}
k <- c(k1, k2) # list of kernels
# function output
out <- gpr_seq_kernels(X, y, k, sigma2, Xt, yt)
pick_kernel(list(1), "se")
#> function(r){
#>     return (exp(-0.5 * (r/l)^2))
#>   }
#> <bytecode: 0x0000029dbefcf788>
#> <environment: 0x0000029dbefda6b8>
pick_kernel(list(2, 3), "m")
#> function (r){
#>     left <-  1 / gamma(v) / 2^(v-1)
#>     mid <- (sqrt(2*v)/ l * r)^ v
#>     right <- besselK(sqrt(2*v) * r / l, nu = v)
#>     return (left * mid * right)
#>   }
#> <bytecode: 0x0000029dbf08a438>
#> <environment: 0x0000029dbf097f30>
library(randomForest)
?randomForest
?predict.randomForest
35/40
36/40
26/40
27/40
28/40
32/40
680/8
12 * 7
9 * 3
12 * 2.4
155/12
143/12
143/9
0.2*16
155/12
setwd("~/Documents/irinagain.github.io")
